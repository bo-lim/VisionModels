{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X1J7RQDVuua9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vxzLnDRa_MEw"
   },
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
    "\n",
    "def _weights_init(m):\n",
    "  classname = m.__class__.__name__\n",
    "  #print(classname)\n",
    "  if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "      init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "  def __init__(self, lambd):\n",
    "    super(LambdaLayer, self).__init__()\n",
    "    self.lambd = lambd\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.lambd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lDZXV1kBuya-"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "  # block 안에서 plane 수 증가 비율\n",
    "  expansion = 1\n",
    "\n",
    "  # in_planes : input, planes: output\n",
    "  def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    \n",
    "    self.dropout = nn.Dropout(0.4)\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes, momentum=0.9)\n",
    "    \n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes, momentum=0.9)\n",
    "    \n",
    "    self.shortcut = nn.Sequential()\n",
    "    # shortcut connection 시 shape가 맞지 않을 때(conv_n 이 conv_n+1로 넘어갈 때)\n",
    "    if stride != 1 or in_planes != planes:\n",
    "        if option == 'A':\n",
    "          # zero padding\n",
    "          self.shortcut = LambdaLayer(lambda x:\n",
    "                                      F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "        elif option == 'B':\n",
    "          # projection\n",
    "          self.shortcut = nn.Sequential(\n",
    "              nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "              nn.BatchNorm2d(self.expansion * planes, momentum=0.9)\n",
    "              )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    # shortcut connection\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RLEKrlJVhFOx"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "  def __init__(self, block, num_blocks, num_classes=10):\n",
    "    super(ResNet, self).__init__()\n",
    "    \n",
    "    self.in_planes = 16\n",
    "\n",
    "    self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(16, momentum=0.9)\n",
    "\n",
    "\n",
    "    # feature map : 32 x 32 x 16\n",
    "    self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "    # feature map : 16 x 16 x 32\n",
    "    self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "    # feature map : 8 x 8 x 64\n",
    "    self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "    # 마지막 클래스 예측 (Linear)\n",
    "    self.fc_out = nn.Linear(64, num_classes)\n",
    "\n",
    "    self.apply(_weights_init)\n",
    "\n",
    "  \n",
    "  def _make_layer(self, block, planes, num_blocks, stride):\n",
    "    # 처음 stride만 2, 이후 1\n",
    "    strides = [stride] + [1]*(num_blocks-1)\n",
    "    layers = []\n",
    "    for stride in strides:\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.layer1(out)\n",
    "    out = self.dropout(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.dropout(out)\n",
    "    out = self.layer3(out)\n",
    "    out = F.avg_pool2d(out, out.size()[3])\n",
    "    out = out.view(out.size(0),-1)\n",
    "    out = self.fc_out(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # block 안에서 plane 수 증가 비율\n",
    "    expansion = 1\n",
    "    momen = 0.8\n",
    "    # in_planes : input, planes: output\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # shortcut connection 시 shape가 맞지 않을 때(conv_n 이 conv_n+1로 넘어갈 때)\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "              # zero padding\n",
    "              self.shortcut = LambdaLayer(lambda x:\n",
    "                                          F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "              # projection\n",
    "              self.shortcut = nn.Sequential(\n",
    "                  nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                  nn.BatchNorm2d(self.expansion * planes, momentum=self.momen)\n",
    "                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.in_planes = 16\n",
    "        self.momen = 0.8\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16, momentum = self.momen)\n",
    "\n",
    "\n",
    "        # feature map : 32 x 32 x 16\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        # feature map : 16 x 16 x 32\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        # feature map : 8 x 8 x 64\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        # 마지막 클래스 예측 (Linear)\n",
    "        self.fc_out = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "  \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        # 처음 stride만 2, 이후 1\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YIHwcIaip-a6"
   },
   "outputs": [],
   "source": [
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "\n",
    "def resnet32():\n",
    "    return ResNet(BasicBlock, [5, 5, 5])\n",
    "\n",
    "\n",
    "def resnet44():\n",
    "    return ResNet(BasicBlock, [7, 7, 7])\n",
    "\n",
    "\n",
    "def resnet56():\n",
    "    return ResNet(BasicBlock, [9, 9, 9])\n",
    "# def resnet56():\n",
    "#     return ResNet(Bottleneck, [9, 9, 9])\n",
    "\n",
    "\n",
    "def resnet110():\n",
    "    return ResNet(BasicBlock, [18, 18, 18])\n",
    "\n",
    "\n",
    "def resnet1202():\n",
    "    return ResNet(BasicBlock, [200, 200, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WxYhPWId2w7D"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fTjGX0wUqAJL"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "d1cf25f46deb4f88826662112d21dc6d",
      "2b07dc78631f41a5ab45326b30578fd2",
      "5a092a21e41f49f9aaef624c65b8f085",
      "b767e221ed574044ac190ae9576a93fb",
      "09690110ef67450d9cb3f5892460d55d",
      "89c276144fb54354b2a3bcfe9ea99d6b",
      "625c653036f7494580a4462aee3c9602",
      "0c0e454d875a48e598ce6c739cf5b0f6"
     ]
    },
    "id": "I6ITQVsX2HoV",
    "outputId": "5055a513-6470-43b6-e3f9-b48e022d0e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "                                      transforms.RandomCrop(32, padding=4),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',train=True,download=True,transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128,shuffle=True,num_workers=2\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',train=False,download=True,transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100,shuffle=False,num_workers=2\n",
    ")\n",
    "classes=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "q9EK9j6q6APG"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'%(train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "99FNest-6VjW"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_accuracy\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    global validation_running_loss_history\n",
    "    global validation_running_correct_history\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            ouputs = net(inputs)\n",
    "            loss = criterion(ouputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = ouputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'%(test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        acc = 100.*correct/total\n",
    "    if acc > best_accuracy:\n",
    "        print('Saving..')\n",
    "        best_accuracy = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             432\n",
      "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
      "            Conv2d-3         [-1, 16, 224, 224]             432\n",
      "       BatchNorm2d-4         [-1, 16, 224, 224]              32\n",
      "            Conv2d-5         [-1, 16, 224, 224]           2,304\n",
      "       BatchNorm2d-6         [-1, 16, 224, 224]              32\n",
      "            Conv2d-7         [-1, 16, 224, 224]           2,304\n",
      "       BatchNorm2d-8         [-1, 16, 224, 224]              32\n",
      "        BasicBlock-9         [-1, 16, 224, 224]               0\n",
      "           Conv2d-10         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-11         [-1, 16, 224, 224]              32\n",
      "           Conv2d-12         [-1, 16, 224, 224]           2,304\n",
      "           Conv2d-13         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-14         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-15         [-1, 16, 224, 224]               0\n",
      "      BatchNorm2d-16         [-1, 16, 224, 224]              32\n",
      "           Conv2d-17         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-18         [-1, 16, 224, 224]              32\n",
      "           Conv2d-19         [-1, 16, 224, 224]           2,304\n",
      "           Conv2d-20         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-21         [-1, 16, 224, 224]              32\n",
      "      BatchNorm2d-22         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-23         [-1, 16, 224, 224]               0\n",
      "       BasicBlock-24         [-1, 16, 224, 224]               0\n",
      "          Dropout-25         [-1, 16, 224, 224]               0\n",
      "           Conv2d-26         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-27         [-1, 16, 224, 224]              32\n",
      "           Conv2d-28         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-29         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-30         [-1, 16, 224, 224]               0\n",
      "           Conv2d-31         [-1, 16, 224, 224]           2,304\n",
      "      BatchNorm2d-32         [-1, 16, 224, 224]              32\n",
      "           Conv2d-33         [-1, 16, 224, 224]           2,304\n",
      "           Conv2d-34         [-1, 32, 112, 112]           4,608\n",
      "      BatchNorm2d-35         [-1, 32, 112, 112]              64\n",
      "      BatchNorm2d-36         [-1, 16, 224, 224]              32\n",
      "       BasicBlock-37         [-1, 16, 224, 224]               0\n",
      "          Dropout-38         [-1, 16, 224, 224]               0\n",
      "           Conv2d-39         [-1, 32, 112, 112]           4,608\n",
      "      BatchNorm2d-40         [-1, 32, 112, 112]              64\n",
      "           Conv2d-41         [-1, 32, 112, 112]           9,216\n",
      "      BatchNorm2d-42         [-1, 32, 112, 112]              64\n",
      "           Conv2d-43         [-1, 32, 112, 112]           9,216\n",
      "           Conv2d-44         [-1, 32, 112, 112]             512\n",
      "      BatchNorm2d-45         [-1, 32, 112, 112]              64\n",
      "      BatchNorm2d-46         [-1, 32, 112, 112]              64\n",
      "       BasicBlock-47         [-1, 32, 112, 112]               0\n",
      "           Conv2d-48         [-1, 32, 112, 112]             512\n",
      "           Conv2d-49         [-1, 32, 112, 112]           9,216\n",
      "      BatchNorm2d-50         [-1, 32, 112, 112]              64\n",
      "      BatchNorm2d-51         [-1, 32, 112, 112]              64\n",
      "       BasicBlock-52         [-1, 32, 112, 112]               0\n",
      "           Conv2d-53         [-1, 32, 112, 112]           9,216\n",
      "      BatchNorm2d-54         [-1, 32, 112, 112]              64\n",
      "           Conv2d-55         [-1, 32, 112, 112]           9,216\n",
      "      BatchNorm2d-56         [-1, 32, 112, 112]              64\n",
      "           Conv2d-57         [-1, 32, 112, 112]           9,216\n",
      "       BasicBlock-58         [-1, 32, 112, 112]               0\n",
      "      BatchNorm2d-59         [-1, 32, 112, 112]              64\n",
      "           Conv2d-60         [-1, 32, 112, 112]           9,216\n",
      "       BasicBlock-61         [-1, 32, 112, 112]               0\n",
      "      BatchNorm2d-62         [-1, 32, 112, 112]              64\n",
      "           Conv2d-63         [-1, 32, 112, 112]           9,216\n",
      "      BatchNorm2d-64         [-1, 32, 112, 112]              64\n",
      "           Conv2d-65         [-1, 32, 112, 112]           9,216\n",
      "      BatchNorm2d-66         [-1, 32, 112, 112]              64\n",
      "           Conv2d-67         [-1, 32, 112, 112]           9,216\n",
      "       BasicBlock-68         [-1, 32, 112, 112]               0\n",
      "          Dropout-69         [-1, 32, 112, 112]               0\n",
      "      BatchNorm2d-70         [-1, 32, 112, 112]              64\n",
      "       BasicBlock-71         [-1, 32, 112, 112]               0\n",
      "          Dropout-72         [-1, 32, 112, 112]               0\n",
      "           Conv2d-73           [-1, 64, 56, 56]          18,432\n",
      "      BatchNorm2d-74           [-1, 64, 56, 56]             128\n",
      "           Conv2d-75           [-1, 64, 56, 56]          18,432\n",
      "      BatchNorm2d-76           [-1, 64, 56, 56]             128\n",
      "           Conv2d-77           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-78           [-1, 64, 56, 56]             128\n",
      "           Conv2d-79           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-80           [-1, 64, 56, 56]             128\n",
      "           Conv2d-81           [-1, 64, 56, 56]           2,048\n",
      "      BatchNorm2d-82           [-1, 64, 56, 56]             128\n",
      "           Conv2d-83           [-1, 64, 56, 56]           2,048\n",
      "       BasicBlock-84           [-1, 64, 56, 56]               0\n",
      "      BatchNorm2d-85           [-1, 64, 56, 56]             128\n",
      "           Conv2d-86           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-87           [-1, 64, 56, 56]             128\n",
      "       BasicBlock-88           [-1, 64, 56, 56]               0\n",
      "           Conv2d-89           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-90           [-1, 64, 56, 56]             128\n",
      "           Conv2d-91           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-92           [-1, 64, 56, 56]             128\n",
      "           Conv2d-93           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-94           [-1, 64, 56, 56]             128\n",
      "       BasicBlock-95           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-96           [-1, 64, 56, 56]               0\n",
      "           Conv2d-97           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-98           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-99           [-1, 64, 56, 56]             128\n",
      "     BatchNorm2d-100           [-1, 64, 56, 56]             128\n",
      "          Conv2d-101           [-1, 64, 56, 56]          36,864\n",
      "          Conv2d-102           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-103           [-1, 64, 56, 56]             128\n",
      "     BatchNorm2d-104           [-1, 64, 56, 56]             128\n",
      "      BasicBlock-105           [-1, 64, 56, 56]               0\n",
      "      BasicBlock-106           [-1, 64, 56, 56]               0\n",
      "          Linear-107                   [-1, 10]             650\n",
      "          Linear-108                   [-1, 10]             650\n",
      "          ResNet-109                   [-1, 10]               0\n",
      "          ResNet-110                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 544,948\n",
      "Trainable params: 544,948\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 382.81\n",
      "Params size (MB): 2.08\n",
      "Estimated Total Size (MB): 385.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(net, input_size=(3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_enEg_oc2qFG"
   },
   "source": [
    "## bn momentum 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJjQ_Fz329AR"
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uZrBaWGnAD0P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy dropout 1개\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaIG5_hr5634"
   },
   "source": [
    "## lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d9Xg3DzrqfRm",
    "outputId": "6783fa45-472f-42fe-9b82-47e1c7ade68d"
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.41"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy dropout 1개\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr->0.1, lr_scheduler = MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "decay_epoch = [100,150]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr 0.1, weight_decay=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [100,150]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.94"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr = 0.0001 and weight_decay=5e-4 no scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001,momentum=0.9, weight_decay=5e-4)\n",
    "decay_epoch = [100,150]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  #scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.42"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler decay epoch 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "decay_epoch = [50,100,150,180]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.73"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decay epoch 3개 sgd weight deacy 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-3)\n",
    "decay_epoch = [100,150,180]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.88"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sgd weight deacy 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-3)\n",
    "\n",
    "decay_epoch = [100,150]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+201):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler gamm = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "decay_epoch = [50,100,150,180]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.05)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+201):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.74"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optim Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "decay_epoch = [150]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+201):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.8, weight_decay=5e-4)\n",
    "decay_epoch = [100,150]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+201):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy dropout 2개, opt : sgd\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model momentum = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # block 안에서 plane 수 증가 비율\n",
    "    expansion = 1\n",
    "    momen = 0.8\n",
    "    # in_planes : input, planes: output\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # shortcut connection 시 shape가 맞지 않을 때(conv_n 이 conv_n+1로 넘어갈 때)\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "              # zero padding\n",
    "              self.shortcut = LambdaLayer(lambda x:\n",
    "                                          F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "              # projection\n",
    "              self.shortcut = nn.Sequential(\n",
    "                  nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                  nn.BatchNorm2d(self.expansion * planes, momentum=self.momen)\n",
    "                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.in_planes = 16\n",
    "        self.momen = 0.8\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16, momentum = self.momen)\n",
    "\n",
    "\n",
    "        # feature map : 32 x 32 x 16\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        # feature map : 16 x 16 x 32\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        # feature map : 8 x 8 x 64\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        # 마지막 클래스 예측 (Linear)\n",
    "        self.fc_out = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "  \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        # 처음 stride만 2, 이후 1\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.8, weight_decay=5e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.46"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QJGpRMfA9Xt"
   },
   "source": [
    "## net momentun 0.8, opt momentum 0.7, weight_decay=3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQk3XJTAMYWU"
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.7, weight_decay=3e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8gyU1wPmEAT",
    "outputId": "e664d739-6dc6-4e93-d311-f1bdd343d46e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.81"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet32의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## net momentun 0.8, opt momentum 0.7, weight_decay=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zylHDEHImJME",
    "outputId": "e8b0ba7c-29f9-4d5e-f1ff-2efacd966d1e"
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.7, weight_decay=5e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zK1KBnjvmUr7",
    "outputId": "ed29786e-6451-4f96-9c8c-8289d6151926"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.27"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet44의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# net momentun 0.8, opt momentum 0.8, weight_decay=5e-4, lr=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.75"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## net momentun 0.8, opt momentum 0.8, weight_decay=5e-4, lr=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.2, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet20의 best_accuracy\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic block momentum: 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # block 안에서 plane 수 증가 비율\n",
    "    expansion = 1\n",
    "    momen = 0.7\n",
    "    # in_planes : input, planes: output\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # shortcut connection 시 shape가 맞지 않을 때(conv_n 이 conv_n+1로 넘어갈 때)\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "              # zero padding\n",
    "              self.shortcut = LambdaLayer(lambda x:\n",
    "                                          F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "              # projection\n",
    "              self.shortcut = nn.Sequential(\n",
    "                  nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                  nn.BatchNorm2d(self.expansion * planes, momentum=self.momen)\n",
    "                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum :0.8 decay epoch 추가 lr:0.155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # block 안에서 plane 수 증가 비율\n",
    "    expansion = 1\n",
    "    momen = 0.8\n",
    "    # in_planes : input, planes: output\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # shortcut connection 시 shape가 맞지 않을 때(conv_n 이 conv_n+1로 넘어갈 때)\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "              # zero padding\n",
    "              self.shortcut = LambdaLayer(lambda x:\n",
    "                                          F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "              # projection\n",
    "              self.shortcut = nn.Sequential(\n",
    "                  nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                  nn.BatchNorm2d(self.expansion * planes, momentum=self.momen)\n",
    "                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.155, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200,230]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.55"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr=0.15, decay epoch만 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200,230]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decay epoch gamma =0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200,230]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.05)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # block 안에서 plane 수 증가 비율\n",
    "    expansion = 1\n",
    "    momen = 0.8\n",
    "    # in_planes : input, planes: output\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # shortcut connection 시 shape가 맞지 않을 때(conv_n 이 conv_n+1로 넘어갈 때)\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "              # zero padding\n",
    "              self.shortcut = LambdaLayer(lambda x:\n",
    "                                          F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "              # projection\n",
    "              self.shortcut = nn.Sequential(\n",
    "                  nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                  nn.BatchNorm2d(self.expansion * planes, momentum=self.momen)\n",
    "                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.34"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option B, decay epoch 200 -> 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # block 안에서 plane 수 증가 비율\n",
    "    expansion = 1\n",
    "    momen = 0.8\n",
    "    # in_planes : input, planes: output\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=self.momen)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # shortcut connection 시 shape가 맞지 않을 때(conv_n 이 conv_n+1로 넘어갈 때)\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "              # zero padding\n",
    "              self.shortcut = LambdaLayer(lambda x:\n",
    "                                          F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "              # projection\n",
    "              self.shortcut = nn.Sequential(\n",
    "                  nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                  nn.BatchNorm2d(self.expansion * planes, momentum=self.momen)\n",
    "                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [110,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.66"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [100,150,220]\n",
    "best_accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr 0.148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.148, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.61"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gamma 0.15 -> 별로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adam lr 0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.52"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sgd momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.75, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.49"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.85, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decay epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [90,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.26"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90, 140, 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.05)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [90,140,190]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "  train(epoch)\n",
    "  test(epoch)\n",
    "  scheduler.step()\n",
    "  print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.52"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,threshold=1e-4,patience=5,factor=0.7,mode='min',verbose=1) \n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.33"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005, weight_decay=5e-4)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,threshold=1e-4,patience=5,factor=0.8,mode='min',verbose=1) \n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-4)\n",
    "decay_epoch = [100,150,200]\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99,verbose=1)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,threshold=1e-4,patience=5,factor=0.8,mode='min',verbose=1) \n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum 0.95 \n",
    "gamma = 0.99 -> 91.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.95, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.95, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.93, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.53"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.97, weight_decay=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.97, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.17"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.98, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.01"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "validation_running_correct_history = []\n",
    "validation_running_loss_history = []\n",
    "\n",
    "net = resnet20()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.85, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.47"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model\n",
    "## 92.75 나왔던 조건으로 resnet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "start_epoch = 0\n",
    "\n",
    "net = resnet32()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15, momentum=0.8, weight_decay=5e-4)\n",
    "\n",
    "decay_epoch = [100,150,200]\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+251):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    print('epoch : ',epoch, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09690110ef67450d9cb3f5892460d55d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0c0e454d875a48e598ce6c739cf5b0f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b07dc78631f41a5ab45326b30578fd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a092a21e41f49f9aaef624c65b8f085": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89c276144fb54354b2a3bcfe9ea99d6b",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09690110ef67450d9cb3f5892460d55d",
      "value": 170498071
     }
    },
    "625c653036f7494580a4462aee3c9602": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89c276144fb54354b2a3bcfe9ea99d6b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b767e221ed574044ac190ae9576a93fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c0e454d875a48e598ce6c739cf5b0f6",
      "placeholder": "​",
      "style": "IPY_MODEL_625c653036f7494580a4462aee3c9602",
      "value": " 170499072/? [00:12&lt;00:00, 13985348.30it/s]"
     }
    },
    "d1cf25f46deb4f88826662112d21dc6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a092a21e41f49f9aaef624c65b8f085",
       "IPY_MODEL_b767e221ed574044ac190ae9576a93fb"
      ],
      "layout": "IPY_MODEL_2b07dc78631f41a5ab45326b30578fd2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
